{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanubv/ML_Zoo/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndZwjav_2RnX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ-R-JIR20FZ"
      },
      "outputs": [],
      "source": [
        "#Downloading the training data and testing data\n",
        "training_data = datasets.FashionMNIST(root = \"data\",\n",
        "                                      train = True,\n",
        "                                      download = True,\n",
        "                                      transform = ToTensor(),\n",
        "                                      #target_transform = Lambda(lambda y_train: torch.zeros(10, dtype = torch.float).scatter_(torch.tensor(y_train), value=1))\n",
        "                                      )\n",
        "\n",
        "testing_data  = datasets.FashionMNIST(root = \"data\",\n",
        "                                      train = False,\n",
        "                                      download = True,\n",
        "                                      transform = ToTensor(),\n",
        "                                      #target_transform = Lambda(lambda y_test: torch.zeros(10, dtype = torch.float).scatter_(torch.tensor(y_test), value =1))\n",
        "                                      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1Gb0zto4Q6y"
      },
      "outputs": [],
      "source": [
        "#creating a dataloader\n",
        "train_dataloader = DataLoader(training_data, batch_size = 64, shuffle =  True)\n",
        "test_dataloader = DataLoader(testing_data, batch_size = 64, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Sl_-QhPf4Q9h",
        "outputId": "9e1416c3-fb35-4c5c-9019-31496d8ecf68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch size is: torch.Size([64, 1, 28, 28])\n",
            "labels batch size is: torch.Size([64])\n",
            "torch.Size([28, 28])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 3\n"
          ]
        }
      ],
      "source": [
        "#Iterating over the dataloader\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Input batch size is: {train_features.size()}\")  #Input batch size is: torch.Size([64, 1, 28, 28])\n",
        "print(f\"labels batch size is: {train_labels.size()}\")   #labels batch size is: torch.Size([64])\n",
        "img = train_features[0].squeeze()\n",
        "print(img.size())\n",
        "labels = train_labels[0]\n",
        "plt.imshow(img, cmap='gray')\n",
        "plt.show()\n",
        "print(f\"Label: {labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (train_features, train_labels) in enumerate(train_dataloader):\n",
        "    print(f\"Batch: {i}, training_batch_size: {train_features.size()}, training_labels_size:{train_labels.size()} \")\n",
        "\"\"\"\n",
        "    img = train_features[0].squeeze()\n",
        "    label = train_labels[0]\n",
        "    plt.imshow(img, cmap = 'gray')\n",
        "    plt.show()\n",
        "    print(f\"Label: {label}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_2G7hbV6K9EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FPoMFIkvrwI"
      },
      "outputs": [],
      "source": [
        "#Creating a Sequential Linear Model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_nw = nn.Sequential(\n",
        "                                       nn.Linear(28*28, 512),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(512, 512),\n",
        "                                       nn.ReLU(),\n",
        "                                       nn.Linear(512, 10),\n",
        "                                       )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_nw(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "model = NeuralNetwork()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oC8LQAE1vrsa"
      },
      "outputs": [],
      "source": [
        "#epochs = 10\n",
        "#learning_rate = 1e-3\n",
        "#loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt0NXiVkvrlS"
      },
      "outputs": [],
      "source": [
        "#Model Training\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (x,y) in enumerate(dataloader):\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch%100 == 0:\n",
        "            loss, counter = loss.item(), (batch+1)*len(x)\n",
        "            print(f\"loss: {loss:>7f} [{counter:>5d}/{size:>5d}]\")\n",
        "\n",
        "#Validating the model over test dataset\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for x, y in dataloader:\n",
        "          pred = model(x)\n",
        "          test_loss += loss_fn(pred, y).item()\n",
        "          correct = correct+(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "\n",
        "\n",
        "    test_loss = test_loss/num_batches\n",
        "    correct = correct/size\n",
        "\n",
        "    print(f\"Test Error:\\n Accuracy {(100*correct) :>0.01f}%, avg_loss {test_loss:>8f}\\n \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YDW1wv7JalM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlobveT70XZm",
        "outputId": "7f5395dd-83f4-4110-fdde-e76a9131b9c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "-----------------------\n",
            "loss: 2.293675 [   64/60000]\n",
            "loss: 2.295318 [ 6464/60000]\n",
            "loss: 2.260496 [12864/60000]\n",
            "loss: 2.268075 [19264/60000]\n",
            "loss: 2.237509 [25664/60000]\n",
            "loss: 2.219941 [32064/60000]\n",
            "loss: 2.199709 [38464/60000]\n",
            "loss: 2.200029 [44864/60000]\n",
            "loss: 2.159387 [51264/60000]\n",
            "loss: 2.165190 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 46.0%, avg_loss 2.147989\n",
            " \n",
            "Epoch: 2\n",
            "-----------------------\n",
            "loss: 2.164121 [   64/60000]\n",
            "loss: 2.109568 [ 6464/60000]\n",
            "loss: 2.120440 [12864/60000]\n",
            "loss: 2.045686 [19264/60000]\n",
            "loss: 2.026602 [25664/60000]\n",
            "loss: 2.071856 [32064/60000]\n",
            "loss: 1.971363 [38464/60000]\n",
            "loss: 1.952997 [44864/60000]\n",
            "loss: 1.961055 [51264/60000]\n",
            "loss: 1.877615 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 55.1%, avg_loss 1.866070\n",
            " \n",
            "Epoch: 3\n",
            "-----------------------\n",
            "loss: 1.837664 [   64/60000]\n",
            "loss: 1.802293 [ 6464/60000]\n",
            "loss: 1.806085 [12864/60000]\n",
            "loss: 1.835619 [19264/60000]\n",
            "loss: 1.712930 [25664/60000]\n",
            "loss: 1.730250 [32064/60000]\n",
            "loss: 1.651266 [38464/60000]\n",
            "loss: 1.659838 [44864/60000]\n",
            "loss: 1.540767 [51264/60000]\n",
            "loss: 1.466822 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 59.3%, avg_loss 1.511437\n",
            " \n",
            "Epoch: 4\n",
            "-----------------------\n",
            "loss: 1.567464 [   64/60000]\n",
            "loss: 1.429787 [ 6464/60000]\n",
            "loss: 1.397799 [12864/60000]\n",
            "loss: 1.431901 [19264/60000]\n",
            "loss: 1.403746 [25664/60000]\n",
            "loss: 1.352221 [32064/60000]\n",
            "loss: 1.392958 [38464/60000]\n",
            "loss: 1.188065 [44864/60000]\n",
            "loss: 1.349440 [51264/60000]\n",
            "loss: 1.305693 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 63.3%, avg_loss 1.260958\n",
            " \n",
            "Epoch: 5\n",
            "-----------------------\n",
            "loss: 1.218200 [   64/60000]\n",
            "loss: 1.228672 [ 6464/60000]\n",
            "loss: 1.228405 [12864/60000]\n",
            "loss: 1.219175 [19264/60000]\n",
            "loss: 1.193158 [25664/60000]\n",
            "loss: 1.035966 [32064/60000]\n",
            "loss: 1.130370 [38464/60000]\n",
            "loss: 1.222901 [44864/60000]\n",
            "loss: 1.215088 [51264/60000]\n",
            "loss: 1.098597 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 65.1%, avg_loss 1.099541\n",
            " \n",
            "Epoch: 6\n",
            "-----------------------\n",
            "loss: 1.058214 [   64/60000]\n",
            "loss: 1.012847 [ 6464/60000]\n",
            "loss: 1.077222 [12864/60000]\n",
            "loss: 0.959169 [19264/60000]\n",
            "loss: 0.963029 [25664/60000]\n",
            "loss: 0.945013 [32064/60000]\n",
            "loss: 0.973108 [38464/60000]\n",
            "loss: 1.059948 [44864/60000]\n",
            "loss: 0.918482 [51264/60000]\n",
            "loss: 0.900573 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 66.2%, avg_loss 0.990868\n",
            " \n",
            "Epoch: 7\n",
            "-----------------------\n",
            "loss: 0.889748 [   64/60000]\n",
            "loss: 1.061333 [ 6464/60000]\n",
            "loss: 1.016566 [12864/60000]\n",
            "loss: 0.990704 [19264/60000]\n",
            "loss: 0.967000 [25664/60000]\n",
            "loss: 0.877944 [32064/60000]\n",
            "loss: 0.997143 [38464/60000]\n",
            "loss: 0.900641 [44864/60000]\n",
            "loss: 0.934985 [51264/60000]\n",
            "loss: 0.786790 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 67.4%, avg_loss 0.917401\n",
            " \n",
            "Epoch: 8\n",
            "-----------------------\n",
            "loss: 0.987550 [   64/60000]\n",
            "loss: 0.796407 [ 6464/60000]\n",
            "loss: 0.917812 [12864/60000]\n",
            "loss: 0.817147 [19264/60000]\n",
            "loss: 0.763296 [25664/60000]\n",
            "loss: 0.822402 [32064/60000]\n",
            "loss: 1.008307 [38464/60000]\n",
            "loss: 0.895556 [44864/60000]\n",
            "loss: 0.816375 [51264/60000]\n",
            "loss: 0.832195 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 69.2%, avg_loss 0.864032\n",
            " \n",
            "Epoch: 9\n",
            "-----------------------\n",
            "loss: 0.861259 [   64/60000]\n",
            "loss: 0.799322 [ 6464/60000]\n",
            "loss: 0.877919 [12864/60000]\n",
            "loss: 0.803837 [19264/60000]\n",
            "loss: 1.133583 [25664/60000]\n",
            "loss: 0.872344 [32064/60000]\n",
            "loss: 0.864626 [38464/60000]\n",
            "loss: 0.777558 [44864/60000]\n",
            "loss: 0.734913 [51264/60000]\n",
            "loss: 0.858762 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 69.6%, avg_loss 0.822320\n",
            " \n",
            "Epoch: 10\n",
            "-----------------------\n",
            "loss: 0.981291 [   64/60000]\n",
            "loss: 0.738497 [ 6464/60000]\n",
            "loss: 0.855223 [12864/60000]\n",
            "loss: 0.727081 [19264/60000]\n",
            "loss: 0.734894 [25664/60000]\n",
            "loss: 0.778737 [32064/60000]\n",
            "loss: 0.759342 [38464/60000]\n",
            "loss: 0.800864 [44864/60000]\n",
            "loss: 0.843279 [51264/60000]\n",
            "loss: 0.815626 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 71.0%, avg_loss 0.788874\n",
            " \n",
            "Epoch: 11\n",
            "-----------------------\n",
            "loss: 0.706225 [   64/60000]\n",
            "loss: 0.888980 [ 6464/60000]\n",
            "loss: 0.678408 [12864/60000]\n",
            "loss: 0.796847 [19264/60000]\n",
            "loss: 0.645346 [25664/60000]\n",
            "loss: 0.840982 [32064/60000]\n",
            "loss: 0.761600 [38464/60000]\n",
            "loss: 0.741503 [44864/60000]\n",
            "loss: 0.778106 [51264/60000]\n",
            "loss: 0.896104 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 72.8%, avg_loss 0.761281\n",
            " \n",
            "Epoch: 12\n",
            "-----------------------\n",
            "loss: 0.578353 [   64/60000]\n",
            "loss: 0.690477 [ 6464/60000]\n",
            "loss: 0.694223 [12864/60000]\n",
            "loss: 0.788601 [19264/60000]\n",
            "loss: 0.752200 [25664/60000]\n",
            "loss: 0.878144 [32064/60000]\n",
            "loss: 0.766516 [38464/60000]\n",
            "loss: 0.888109 [44864/60000]\n",
            "loss: 0.682180 [51264/60000]\n",
            "loss: 0.723401 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 73.7%, avg_loss 0.740057\n",
            " \n",
            "Epoch: 13\n",
            "-----------------------\n",
            "loss: 0.710728 [   64/60000]\n",
            "loss: 0.792887 [ 6464/60000]\n",
            "loss: 0.630146 [12864/60000]\n",
            "loss: 0.630493 [19264/60000]\n",
            "loss: 0.735234 [25664/60000]\n",
            "loss: 0.735615 [32064/60000]\n",
            "loss: 0.652666 [38464/60000]\n",
            "loss: 0.697128 [44864/60000]\n",
            "loss: 0.684450 [51264/60000]\n",
            "loss: 0.829593 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 74.5%, avg_loss 0.720966\n",
            " \n",
            "Epoch: 14\n",
            "-----------------------\n",
            "loss: 0.640984 [   64/60000]\n",
            "loss: 0.766869 [ 6464/60000]\n",
            "loss: 0.749535 [12864/60000]\n",
            "loss: 0.552978 [19264/60000]\n",
            "loss: 0.606784 [25664/60000]\n",
            "loss: 0.741716 [32064/60000]\n",
            "loss: 0.678790 [38464/60000]\n",
            "loss: 0.667066 [44864/60000]\n",
            "loss: 0.507565 [51264/60000]\n",
            "loss: 0.826890 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 75.3%, avg_loss 0.700810\n",
            " \n",
            "Epoch: 15\n",
            "-----------------------\n",
            "loss: 0.771001 [   64/60000]\n",
            "loss: 0.686300 [ 6464/60000]\n",
            "loss: 0.628771 [12864/60000]\n",
            "loss: 0.673443 [19264/60000]\n",
            "loss: 0.648508 [25664/60000]\n",
            "loss: 0.527580 [32064/60000]\n",
            "loss: 0.698221 [38464/60000]\n",
            "loss: 0.801080 [44864/60000]\n",
            "loss: 0.758426 [51264/60000]\n",
            "loss: 0.816458 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 75.7%, avg_loss 0.685596\n",
            " \n",
            "Epoch: 16\n",
            "-----------------------\n",
            "loss: 0.629603 [   64/60000]\n",
            "loss: 0.632928 [ 6464/60000]\n",
            "loss: 0.798486 [12864/60000]\n",
            "loss: 0.687216 [19264/60000]\n",
            "loss: 0.863328 [25664/60000]\n",
            "loss: 0.691858 [32064/60000]\n",
            "loss: 0.684523 [38464/60000]\n",
            "loss: 0.657760 [44864/60000]\n",
            "loss: 0.575252 [51264/60000]\n",
            "loss: 0.698219 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 76.2%, avg_loss 0.671943\n",
            " \n",
            "Epoch: 17\n",
            "-----------------------\n",
            "loss: 0.801524 [   64/60000]\n",
            "loss: 0.734810 [ 6464/60000]\n",
            "loss: 0.522286 [12864/60000]\n",
            "loss: 0.602666 [19264/60000]\n",
            "loss: 0.598100 [25664/60000]\n",
            "loss: 0.604236 [32064/60000]\n",
            "loss: 0.613332 [38464/60000]\n",
            "loss: 0.683484 [44864/60000]\n",
            "loss: 0.594947 [51264/60000]\n",
            "loss: 0.613179 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 77.0%, avg_loss 0.654466\n",
            " \n",
            "Epoch: 18\n",
            "-----------------------\n",
            "loss: 0.702341 [   64/60000]\n",
            "loss: 0.635078 [ 6464/60000]\n",
            "loss: 0.624503 [12864/60000]\n",
            "loss: 0.536344 [19264/60000]\n",
            "loss: 0.697720 [25664/60000]\n",
            "loss: 0.577606 [32064/60000]\n",
            "loss: 0.598658 [38464/60000]\n",
            "loss: 0.402413 [44864/60000]\n",
            "loss: 0.855780 [51264/60000]\n",
            "loss: 0.579631 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 77.4%, avg_loss 0.642647\n",
            " \n",
            "Epoch: 19\n",
            "-----------------------\n",
            "loss: 0.504757 [   64/60000]\n",
            "loss: 0.621534 [ 6464/60000]\n",
            "loss: 0.617823 [12864/60000]\n",
            "loss: 0.486521 [19264/60000]\n",
            "loss: 0.618774 [25664/60000]\n",
            "loss: 0.423645 [32064/60000]\n",
            "loss: 0.869239 [38464/60000]\n",
            "loss: 0.539169 [44864/60000]\n",
            "loss: 0.537061 [51264/60000]\n",
            "loss: 0.510903 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 77.9%, avg_loss 0.632406\n",
            " \n",
            "Epoch: 20\n",
            "-----------------------\n",
            "loss: 0.648785 [   64/60000]\n",
            "loss: 0.578197 [ 6464/60000]\n",
            "loss: 0.659873 [12864/60000]\n",
            "loss: 0.593281 [19264/60000]\n",
            "loss: 0.506125 [25664/60000]\n",
            "loss: 0.680200 [32064/60000]\n",
            "loss: 0.622676 [38464/60000]\n",
            "loss: 0.606223 [44864/60000]\n",
            "loss: 0.806702 [51264/60000]\n",
            "loss: 0.737793 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 78.0%, avg_loss 0.622744\n",
            " \n",
            "Epoch: 21\n",
            "-----------------------\n",
            "loss: 0.443378 [   64/60000]\n",
            "loss: 0.521636 [ 6464/60000]\n",
            "loss: 0.800284 [12864/60000]\n",
            "loss: 0.602623 [19264/60000]\n",
            "loss: 0.645688 [25664/60000]\n",
            "loss: 0.502121 [32064/60000]\n",
            "loss: 0.438950 [38464/60000]\n",
            "loss: 0.648855 [44864/60000]\n",
            "loss: 0.618244 [51264/60000]\n",
            "loss: 0.577512 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 78.6%, avg_loss 0.611809\n",
            " \n",
            "Epoch: 22\n",
            "-----------------------\n",
            "loss: 0.667415 [   64/60000]\n",
            "loss: 0.667691 [ 6464/60000]\n",
            "loss: 0.624303 [12864/60000]\n",
            "loss: 0.370140 [19264/60000]\n",
            "loss: 0.758870 [25664/60000]\n",
            "loss: 0.494638 [32064/60000]\n",
            "loss: 0.576903 [38464/60000]\n",
            "loss: 0.805234 [44864/60000]\n",
            "loss: 0.601628 [51264/60000]\n",
            "loss: 0.511223 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 78.7%, avg_loss 0.603174\n",
            " \n",
            "Epoch: 23\n",
            "-----------------------\n",
            "loss: 0.575063 [   64/60000]\n",
            "loss: 0.588788 [ 6464/60000]\n",
            "loss: 0.536461 [12864/60000]\n",
            "loss: 0.514071 [19264/60000]\n",
            "loss: 0.517308 [25664/60000]\n",
            "loss: 0.450803 [32064/60000]\n",
            "loss: 0.661755 [38464/60000]\n",
            "loss: 0.456005 [44864/60000]\n",
            "loss: 0.514747 [51264/60000]\n",
            "loss: 0.610311 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 79.2%, avg_loss 0.595656\n",
            " \n",
            "Epoch: 24\n",
            "-----------------------\n",
            "loss: 0.639746 [   64/60000]\n",
            "loss: 0.614318 [ 6464/60000]\n",
            "loss: 0.536284 [12864/60000]\n",
            "loss: 0.452855 [19264/60000]\n",
            "loss: 0.576606 [25664/60000]\n",
            "loss: 0.615831 [32064/60000]\n",
            "loss: 0.421416 [38464/60000]\n",
            "loss: 0.403821 [44864/60000]\n",
            "loss: 0.498520 [51264/60000]\n",
            "loss: 0.486931 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 79.4%, avg_loss 0.585759\n",
            " \n",
            "Epoch: 25\n",
            "-----------------------\n",
            "loss: 0.618179 [   64/60000]\n",
            "loss: 0.563790 [ 6464/60000]\n",
            "loss: 0.444182 [12864/60000]\n",
            "loss: 0.642824 [19264/60000]\n",
            "loss: 0.488815 [25664/60000]\n",
            "loss: 0.605368 [32064/60000]\n",
            "loss: 0.547771 [38464/60000]\n",
            "loss: 0.604675 [44864/60000]\n",
            "loss: 0.726685 [51264/60000]\n",
            "loss: 0.574524 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 79.6%, avg_loss 0.580423\n",
            " \n",
            "Epoch: 26\n",
            "-----------------------\n",
            "loss: 0.716864 [   64/60000]\n",
            "loss: 0.489370 [ 6464/60000]\n",
            "loss: 0.552968 [12864/60000]\n",
            "loss: 0.568304 [19264/60000]\n",
            "loss: 0.501282 [25664/60000]\n",
            "loss: 0.635229 [32064/60000]\n",
            "loss: 0.521909 [38464/60000]\n",
            "loss: 0.514046 [44864/60000]\n",
            "loss: 0.450560 [51264/60000]\n",
            "loss: 0.611383 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 79.9%, avg_loss 0.572541\n",
            " \n",
            "Epoch: 27\n",
            "-----------------------\n",
            "loss: 0.548278 [   64/60000]\n",
            "loss: 0.655097 [ 6464/60000]\n",
            "loss: 0.430388 [12864/60000]\n",
            "loss: 0.449496 [19264/60000]\n",
            "loss: 0.469601 [25664/60000]\n",
            "loss: 0.476599 [32064/60000]\n",
            "loss: 0.518257 [38464/60000]\n",
            "loss: 0.622190 [44864/60000]\n",
            "loss: 0.509498 [51264/60000]\n",
            "loss: 0.593794 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 80.1%, avg_loss 0.567868\n",
            " \n",
            "Epoch: 28\n",
            "-----------------------\n",
            "loss: 0.678967 [   64/60000]\n",
            "loss: 0.564250 [ 6464/60000]\n",
            "loss: 0.582380 [12864/60000]\n",
            "loss: 0.484226 [19264/60000]\n",
            "loss: 0.659978 [25664/60000]\n",
            "loss: 0.631970 [32064/60000]\n",
            "loss: 0.497217 [38464/60000]\n",
            "loss: 0.475554 [44864/60000]\n",
            "loss: 0.717450 [51264/60000]\n",
            "loss: 0.352445 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 80.4%, avg_loss 0.561953\n",
            " \n",
            "Epoch: 29\n",
            "-----------------------\n",
            "loss: 0.776875 [   64/60000]\n",
            "loss: 0.773456 [ 6464/60000]\n",
            "loss: 0.639827 [12864/60000]\n",
            "loss: 0.537435 [19264/60000]\n",
            "loss: 0.728833 [25664/60000]\n",
            "loss: 0.474760 [32064/60000]\n",
            "loss: 0.528634 [38464/60000]\n",
            "loss: 0.446112 [44864/60000]\n",
            "loss: 0.479748 [51264/60000]\n",
            "loss: 0.649636 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 80.5%, avg_loss 0.556482\n",
            " \n",
            "Epoch: 30\n",
            "-----------------------\n",
            "loss: 0.572847 [   64/60000]\n",
            "loss: 0.658861 [ 6464/60000]\n",
            "loss: 0.729887 [12864/60000]\n",
            "loss: 0.436834 [19264/60000]\n",
            "loss: 0.432739 [25664/60000]\n",
            "loss: 0.492138 [32064/60000]\n",
            "loss: 0.508387 [38464/60000]\n",
            "loss: 0.484910 [44864/60000]\n",
            "loss: 0.501979 [51264/60000]\n",
            "loss: 0.469288 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 80.7%, avg_loss 0.549637\n",
            " \n",
            "Epoch: 31\n",
            "-----------------------\n",
            "loss: 0.527222 [   64/60000]\n",
            "loss: 0.546611 [ 6464/60000]\n",
            "loss: 0.458317 [12864/60000]\n",
            "loss: 0.361326 [19264/60000]\n",
            "loss: 0.510733 [25664/60000]\n",
            "loss: 0.525490 [32064/60000]\n",
            "loss: 0.391471 [38464/60000]\n",
            "loss: 0.609048 [44864/60000]\n",
            "loss: 0.376724 [51264/60000]\n",
            "loss: 0.674343 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.0%, avg_loss 0.547278\n",
            " \n",
            "Epoch: 32\n",
            "-----------------------\n",
            "loss: 0.553380 [   64/60000]\n",
            "loss: 0.439133 [ 6464/60000]\n",
            "loss: 0.804007 [12864/60000]\n",
            "loss: 0.475642 [19264/60000]\n",
            "loss: 0.433400 [25664/60000]\n",
            "loss: 0.519873 [32064/60000]\n",
            "loss: 0.589678 [38464/60000]\n",
            "loss: 0.384651 [44864/60000]\n",
            "loss: 0.602699 [51264/60000]\n",
            "loss: 0.551094 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.1%, avg_loss 0.539182\n",
            " \n",
            "Epoch: 33\n",
            "-----------------------\n",
            "loss: 0.512093 [   64/60000]\n",
            "loss: 0.427785 [ 6464/60000]\n",
            "loss: 0.668603 [12864/60000]\n",
            "loss: 0.347193 [19264/60000]\n",
            "loss: 0.398678 [25664/60000]\n",
            "loss: 0.339633 [32064/60000]\n",
            "loss: 0.750319 [38464/60000]\n",
            "loss: 0.459756 [44864/60000]\n",
            "loss: 0.518578 [51264/60000]\n",
            "loss: 0.496341 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.2%, avg_loss 0.537230\n",
            " \n",
            "Epoch: 34\n",
            "-----------------------\n",
            "loss: 0.506634 [   64/60000]\n",
            "loss: 0.583738 [ 6464/60000]\n",
            "loss: 0.473660 [12864/60000]\n",
            "loss: 0.622332 [19264/60000]\n",
            "loss: 0.454262 [25664/60000]\n",
            "loss: 0.428537 [32064/60000]\n",
            "loss: 0.423388 [38464/60000]\n",
            "loss: 0.590640 [44864/60000]\n",
            "loss: 0.441212 [51264/60000]\n",
            "loss: 0.581074 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.2%, avg_loss 0.533216\n",
            " \n",
            "Epoch: 35\n",
            "-----------------------\n",
            "loss: 0.453827 [   64/60000]\n",
            "loss: 0.551907 [ 6464/60000]\n",
            "loss: 0.375005 [12864/60000]\n",
            "loss: 0.481570 [19264/60000]\n",
            "loss: 0.505789 [25664/60000]\n",
            "loss: 0.430061 [32064/60000]\n",
            "loss: 0.532371 [38464/60000]\n",
            "loss: 0.520711 [44864/60000]\n",
            "loss: 0.507492 [51264/60000]\n",
            "loss: 0.560398 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.4%, avg_loss 0.528822\n",
            " \n",
            "Epoch: 36\n",
            "-----------------------\n",
            "loss: 0.600723 [   64/60000]\n",
            "loss: 0.480379 [ 6464/60000]\n",
            "loss: 0.359554 [12864/60000]\n",
            "loss: 0.461435 [19264/60000]\n",
            "loss: 0.404508 [25664/60000]\n",
            "loss: 0.398393 [32064/60000]\n",
            "loss: 0.448122 [38464/60000]\n",
            "loss: 0.441023 [44864/60000]\n",
            "loss: 0.477875 [51264/60000]\n",
            "loss: 0.428751 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.7%, avg_loss 0.526541\n",
            " \n",
            "Epoch: 37\n",
            "-----------------------\n",
            "loss: 0.628233 [   64/60000]\n",
            "loss: 0.513881 [ 6464/60000]\n",
            "loss: 0.726842 [12864/60000]\n",
            "loss: 0.431372 [19264/60000]\n",
            "loss: 0.736306 [25664/60000]\n",
            "loss: 0.456942 [32064/60000]\n",
            "loss: 0.499876 [38464/60000]\n",
            "loss: 0.594323 [44864/60000]\n",
            "loss: 0.541905 [51264/60000]\n",
            "loss: 0.607568 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.4%, avg_loss 0.523821\n",
            " \n",
            "Epoch: 38\n",
            "-----------------------\n",
            "loss: 0.500776 [   64/60000]\n",
            "loss: 0.603253 [ 6464/60000]\n",
            "loss: 0.479506 [12864/60000]\n",
            "loss: 0.542284 [19264/60000]\n",
            "loss: 0.533635 [25664/60000]\n",
            "loss: 0.385629 [32064/60000]\n",
            "loss: 0.442228 [38464/60000]\n",
            "loss: 0.364205 [44864/60000]\n",
            "loss: 0.624999 [51264/60000]\n",
            "loss: 0.675423 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.8%, avg_loss 0.521837\n",
            " \n",
            "Epoch: 39\n",
            "-----------------------\n",
            "loss: 0.628676 [   64/60000]\n",
            "loss: 0.482031 [ 6464/60000]\n",
            "loss: 0.656901 [12864/60000]\n",
            "loss: 0.466409 [19264/60000]\n",
            "loss: 0.466713 [25664/60000]\n",
            "loss: 0.463892 [32064/60000]\n",
            "loss: 0.452711 [38464/60000]\n",
            "loss: 0.583984 [44864/60000]\n",
            "loss: 0.508300 [51264/60000]\n",
            "loss: 0.383255 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.1%, avg_loss 0.516029\n",
            " \n",
            "Epoch: 40\n",
            "-----------------------\n",
            "loss: 0.624979 [   64/60000]\n",
            "loss: 0.349525 [ 6464/60000]\n",
            "loss: 0.441366 [12864/60000]\n",
            "loss: 0.513560 [19264/60000]\n",
            "loss: 0.406212 [25664/60000]\n",
            "loss: 0.415653 [32064/60000]\n",
            "loss: 0.532538 [38464/60000]\n",
            "loss: 0.620367 [44864/60000]\n",
            "loss: 0.466956 [51264/60000]\n",
            "loss: 0.694477 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 81.7%, avg_loss 0.518957\n",
            " \n",
            "Epoch: 41\n",
            "-----------------------\n",
            "loss: 0.376818 [   64/60000]\n",
            "loss: 0.435755 [ 6464/60000]\n",
            "loss: 0.634165 [12864/60000]\n",
            "loss: 0.479942 [19264/60000]\n",
            "loss: 0.465562 [25664/60000]\n",
            "loss: 0.396828 [32064/60000]\n",
            "loss: 0.616230 [38464/60000]\n",
            "loss: 0.577457 [44864/60000]\n",
            "loss: 0.571457 [51264/60000]\n",
            "loss: 0.605722 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.0%, avg_loss 0.513555\n",
            " \n",
            "Epoch: 42\n",
            "-----------------------\n",
            "loss: 0.548895 [   64/60000]\n",
            "loss: 0.491624 [ 6464/60000]\n",
            "loss: 0.296349 [12864/60000]\n",
            "loss: 0.419245 [19264/60000]\n",
            "loss: 0.397463 [25664/60000]\n",
            "loss: 0.612492 [32064/60000]\n",
            "loss: 0.401768 [38464/60000]\n",
            "loss: 0.420570 [44864/60000]\n",
            "loss: 0.577257 [51264/60000]\n",
            "loss: 0.526057 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.1%, avg_loss 0.508365\n",
            " \n",
            "Epoch: 43\n",
            "-----------------------\n",
            "loss: 0.601299 [   64/60000]\n",
            "loss: 0.474468 [ 6464/60000]\n",
            "loss: 0.640572 [12864/60000]\n",
            "loss: 0.513474 [19264/60000]\n",
            "loss: 0.651562 [25664/60000]\n",
            "loss: 0.349886 [32064/60000]\n",
            "loss: 0.287415 [38464/60000]\n",
            "loss: 0.359926 [44864/60000]\n",
            "loss: 0.437702 [51264/60000]\n",
            "loss: 0.510587 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.2%, avg_loss 0.508248\n",
            " \n",
            "Epoch: 44\n",
            "-----------------------\n",
            "loss: 0.371403 [   64/60000]\n",
            "loss: 0.673555 [ 6464/60000]\n",
            "loss: 0.598072 [12864/60000]\n",
            "loss: 0.436590 [19264/60000]\n",
            "loss: 0.351843 [25664/60000]\n",
            "loss: 0.539899 [32064/60000]\n",
            "loss: 0.576404 [38464/60000]\n",
            "loss: 0.342518 [44864/60000]\n",
            "loss: 0.420875 [51264/60000]\n",
            "loss: 0.368456 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.3%, avg_loss 0.503665\n",
            " \n",
            "Epoch: 45\n",
            "-----------------------\n",
            "loss: 0.456618 [   64/60000]\n",
            "loss: 0.411911 [ 6464/60000]\n",
            "loss: 0.599502 [12864/60000]\n",
            "loss: 0.453120 [19264/60000]\n",
            "loss: 0.404613 [25664/60000]\n",
            "loss: 0.559696 [32064/60000]\n",
            "loss: 0.301592 [38464/60000]\n",
            "loss: 0.327188 [44864/60000]\n",
            "loss: 0.514589 [51264/60000]\n",
            "loss: 0.352782 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.2%, avg_loss 0.502273\n",
            " \n",
            "Epoch: 46\n",
            "-----------------------\n",
            "loss: 0.630818 [   64/60000]\n",
            "loss: 0.613507 [ 6464/60000]\n",
            "loss: 0.339385 [12864/60000]\n",
            "loss: 0.425885 [19264/60000]\n",
            "loss: 0.381923 [25664/60000]\n",
            "loss: 0.404912 [32064/60000]\n",
            "loss: 0.469947 [38464/60000]\n",
            "loss: 0.459689 [44864/60000]\n",
            "loss: 0.403304 [51264/60000]\n",
            "loss: 0.452060 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.5%, avg_loss 0.501699\n",
            " \n",
            "Epoch: 47\n",
            "-----------------------\n",
            "loss: 0.710465 [   64/60000]\n",
            "loss: 0.511891 [ 6464/60000]\n",
            "loss: 0.451708 [12864/60000]\n",
            "loss: 0.588456 [19264/60000]\n",
            "loss: 0.396329 [25664/60000]\n",
            "loss: 0.451310 [32064/60000]\n",
            "loss: 0.588827 [38464/60000]\n",
            "loss: 0.782305 [44864/60000]\n",
            "loss: 0.393474 [51264/60000]\n",
            "loss: 0.457181 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.4%, avg_loss 0.496787\n",
            " \n",
            "Epoch: 48\n",
            "-----------------------\n",
            "loss: 0.370906 [   64/60000]\n",
            "loss: 0.421585 [ 6464/60000]\n",
            "loss: 0.370565 [12864/60000]\n",
            "loss: 0.288291 [19264/60000]\n",
            "loss: 0.468004 [25664/60000]\n",
            "loss: 0.581655 [32064/60000]\n",
            "loss: 0.348990 [38464/60000]\n",
            "loss: 0.455063 [44864/60000]\n",
            "loss: 0.470624 [51264/60000]\n",
            "loss: 0.563420 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.5%, avg_loss 0.498340\n",
            " \n",
            "Epoch: 49\n",
            "-----------------------\n",
            "loss: 0.505115 [   64/60000]\n",
            "loss: 0.584110 [ 6464/60000]\n",
            "loss: 0.459187 [12864/60000]\n",
            "loss: 0.395067 [19264/60000]\n",
            "loss: 0.650463 [25664/60000]\n",
            "loss: 0.560193 [32064/60000]\n",
            "loss: 0.583252 [38464/60000]\n",
            "loss: 0.409447 [44864/60000]\n",
            "loss: 0.361136 [51264/60000]\n",
            "loss: 0.478194 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.6%, avg_loss 0.498257\n",
            " \n",
            "Epoch: 50\n",
            "-----------------------\n",
            "loss: 0.601659 [   64/60000]\n",
            "loss: 0.352726 [ 6464/60000]\n",
            "loss: 0.554344 [12864/60000]\n",
            "loss: 0.396956 [19264/60000]\n",
            "loss: 0.445004 [25664/60000]\n",
            "loss: 0.668133 [32064/60000]\n",
            "loss: 0.478159 [38464/60000]\n",
            "loss: 0.318392 [44864/60000]\n",
            "loss: 0.387149 [51264/60000]\n",
            "loss: 0.434355 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.5%, avg_loss 0.491183\n",
            " \n",
            "Epoch: 51\n",
            "-----------------------\n",
            "loss: 0.638864 [   64/60000]\n",
            "loss: 0.400483 [ 6464/60000]\n",
            "loss: 0.599809 [12864/60000]\n",
            "loss: 0.383511 [19264/60000]\n",
            "loss: 0.467794 [25664/60000]\n",
            "loss: 0.521472 [32064/60000]\n",
            "loss: 0.388902 [38464/60000]\n",
            "loss: 0.411078 [44864/60000]\n",
            "loss: 0.334047 [51264/60000]\n",
            "loss: 0.347019 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.7%, avg_loss 0.493131\n",
            " \n",
            "Epoch: 52\n",
            "-----------------------\n",
            "loss: 0.254691 [   64/60000]\n",
            "loss: 0.472466 [ 6464/60000]\n",
            "loss: 0.383073 [12864/60000]\n",
            "loss: 0.498856 [19264/60000]\n",
            "loss: 0.380246 [25664/60000]\n",
            "loss: 0.386568 [32064/60000]\n",
            "loss: 0.391934 [38464/60000]\n",
            "loss: 0.433665 [44864/60000]\n",
            "loss: 0.510802 [51264/60000]\n",
            "loss: 0.284969 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.7%, avg_loss 0.488634\n",
            " \n",
            "Epoch: 53\n",
            "-----------------------\n",
            "loss: 0.489392 [   64/60000]\n",
            "loss: 0.451809 [ 6464/60000]\n",
            "loss: 0.515951 [12864/60000]\n",
            "loss: 0.417878 [19264/60000]\n",
            "loss: 0.394682 [25664/60000]\n",
            "loss: 0.381065 [32064/60000]\n",
            "loss: 0.502619 [38464/60000]\n",
            "loss: 0.460128 [44864/60000]\n",
            "loss: 0.482582 [51264/60000]\n",
            "loss: 0.466217 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.8%, avg_loss 0.487936\n",
            " \n",
            "Epoch: 54\n",
            "-----------------------\n",
            "loss: 0.319808 [   64/60000]\n",
            "loss: 0.367885 [ 6464/60000]\n",
            "loss: 0.373870 [12864/60000]\n",
            "loss: 0.329187 [19264/60000]\n",
            "loss: 0.397608 [25664/60000]\n",
            "loss: 0.472989 [32064/60000]\n",
            "loss: 0.495855 [38464/60000]\n",
            "loss: 0.503806 [44864/60000]\n",
            "loss: 0.553029 [51264/60000]\n",
            "loss: 0.271540 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.8%, avg_loss 0.484944\n",
            " \n",
            "Epoch: 55\n",
            "-----------------------\n",
            "loss: 0.275019 [   64/60000]\n",
            "loss: 0.768821 [ 6464/60000]\n",
            "loss: 0.429891 [12864/60000]\n",
            "loss: 0.403590 [19264/60000]\n",
            "loss: 0.361957 [25664/60000]\n",
            "loss: 0.547275 [32064/60000]\n",
            "loss: 0.574414 [38464/60000]\n",
            "loss: 0.512274 [44864/60000]\n",
            "loss: 0.303169 [51264/60000]\n",
            "loss: 0.348021 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 82.9%, avg_loss 0.484627\n",
            " \n",
            "Epoch: 56\n",
            "-----------------------\n",
            "loss: 0.580956 [   64/60000]\n",
            "loss: 0.468753 [ 6464/60000]\n",
            "loss: 0.395333 [12864/60000]\n",
            "loss: 0.515898 [19264/60000]\n",
            "loss: 0.456592 [25664/60000]\n",
            "loss: 0.470295 [32064/60000]\n",
            "loss: 0.503263 [38464/60000]\n",
            "loss: 0.257308 [44864/60000]\n",
            "loss: 0.353303 [51264/60000]\n",
            "loss: 0.498890 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.0%, avg_loss 0.482628\n",
            " \n",
            "Epoch: 57\n",
            "-----------------------\n",
            "loss: 0.608687 [   64/60000]\n",
            "loss: 0.475682 [ 6464/60000]\n",
            "loss: 0.522316 [12864/60000]\n",
            "loss: 0.262520 [19264/60000]\n",
            "loss: 0.454356 [25664/60000]\n",
            "loss: 0.450643 [32064/60000]\n",
            "loss: 0.475012 [38464/60000]\n",
            "loss: 0.500379 [44864/60000]\n",
            "loss: 0.482915 [51264/60000]\n",
            "loss: 0.488046 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.0%, avg_loss 0.482173\n",
            " \n",
            "Epoch: 58\n",
            "-----------------------\n",
            "loss: 0.556991 [   64/60000]\n",
            "loss: 0.455022 [ 6464/60000]\n",
            "loss: 0.486715 [12864/60000]\n",
            "loss: 0.330683 [19264/60000]\n",
            "loss: 0.455239 [25664/60000]\n",
            "loss: 0.407964 [32064/60000]\n",
            "loss: 0.491333 [38464/60000]\n",
            "loss: 0.316815 [44864/60000]\n",
            "loss: 0.421207 [51264/60000]\n",
            "loss: 0.477957 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.0%, avg_loss 0.480993\n",
            " \n",
            "Epoch: 59\n",
            "-----------------------\n",
            "loss: 0.358463 [   64/60000]\n",
            "loss: 0.421286 [ 6464/60000]\n",
            "loss: 0.310941 [12864/60000]\n",
            "loss: 0.559882 [19264/60000]\n",
            "loss: 0.435702 [25664/60000]\n",
            "loss: 0.388020 [32064/60000]\n",
            "loss: 0.384568 [38464/60000]\n",
            "loss: 0.324069 [44864/60000]\n",
            "loss: 0.393189 [51264/60000]\n",
            "loss: 0.466394 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.0%, avg_loss 0.477649\n",
            " \n",
            "Epoch: 60\n",
            "-----------------------\n",
            "loss: 0.365010 [   64/60000]\n",
            "loss: 0.466875 [ 6464/60000]\n",
            "loss: 0.481510 [12864/60000]\n",
            "loss: 0.396988 [19264/60000]\n",
            "loss: 0.562687 [25664/60000]\n",
            "loss: 0.238072 [32064/60000]\n",
            "loss: 0.543860 [38464/60000]\n",
            "loss: 0.427489 [44864/60000]\n",
            "loss: 0.463246 [51264/60000]\n",
            "loss: 0.704427 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.1%, avg_loss 0.478838\n",
            " \n",
            "Epoch: 61\n",
            "-----------------------\n",
            "loss: 0.385685 [   64/60000]\n",
            "loss: 0.321290 [ 6464/60000]\n",
            "loss: 0.551530 [12864/60000]\n",
            "loss: 0.579945 [19264/60000]\n",
            "loss: 0.368086 [25664/60000]\n",
            "loss: 0.386511 [32064/60000]\n",
            "loss: 0.451734 [38464/60000]\n",
            "loss: 0.258485 [44864/60000]\n",
            "loss: 0.405159 [51264/60000]\n",
            "loss: 0.534287 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.2%, avg_loss 0.476058\n",
            " \n",
            "Epoch: 62\n",
            "-----------------------\n",
            "loss: 0.329941 [   64/60000]\n",
            "loss: 0.457714 [ 6464/60000]\n",
            "loss: 0.405350 [12864/60000]\n",
            "loss: 0.576348 [19264/60000]\n",
            "loss: 0.532180 [25664/60000]\n",
            "loss: 0.453855 [32064/60000]\n",
            "loss: 0.329510 [38464/60000]\n",
            "loss: 0.331670 [44864/60000]\n",
            "loss: 0.531566 [51264/60000]\n",
            "loss: 0.406492 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.2%, avg_loss 0.473909\n",
            " \n",
            "Epoch: 63\n",
            "-----------------------\n",
            "loss: 0.414030 [   64/60000]\n",
            "loss: 0.464564 [ 6464/60000]\n",
            "loss: 0.472763 [12864/60000]\n",
            "loss: 0.441122 [19264/60000]\n",
            "loss: 0.392472 [25664/60000]\n",
            "loss: 0.360421 [32064/60000]\n",
            "loss: 0.562644 [38464/60000]\n",
            "loss: 0.486621 [44864/60000]\n",
            "loss: 0.725145 [51264/60000]\n",
            "loss: 0.648792 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.3%, avg_loss 0.473412\n",
            " \n",
            "Epoch: 64\n",
            "-----------------------\n",
            "loss: 0.488298 [   64/60000]\n",
            "loss: 0.341570 [ 6464/60000]\n",
            "loss: 0.462888 [12864/60000]\n",
            "loss: 0.316750 [19264/60000]\n",
            "loss: 0.348490 [25664/60000]\n",
            "loss: 0.522205 [32064/60000]\n",
            "loss: 0.385294 [38464/60000]\n",
            "loss: 0.392463 [44864/60000]\n",
            "loss: 0.383334 [51264/60000]\n",
            "loss: 0.442763 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.2%, avg_loss 0.471688\n",
            " \n",
            "Epoch: 65\n",
            "-----------------------\n",
            "loss: 0.479372 [   64/60000]\n",
            "loss: 0.659651 [ 6464/60000]\n",
            "loss: 0.372150 [12864/60000]\n",
            "loss: 0.341845 [19264/60000]\n",
            "loss: 0.415708 [25664/60000]\n",
            "loss: 0.348223 [32064/60000]\n",
            "loss: 0.491268 [38464/60000]\n",
            "loss: 0.315128 [44864/60000]\n",
            "loss: 0.443604 [51264/60000]\n",
            "loss: 0.405185 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.1%, avg_loss 0.471235\n",
            " \n",
            "Epoch: 66\n",
            "-----------------------\n",
            "loss: 0.475969 [   64/60000]\n",
            "loss: 0.627019 [ 6464/60000]\n",
            "loss: 0.520677 [12864/60000]\n",
            "loss: 0.563652 [19264/60000]\n",
            "loss: 0.385591 [25664/60000]\n",
            "loss: 0.464868 [32064/60000]\n",
            "loss: 0.340503 [38464/60000]\n",
            "loss: 0.453226 [44864/60000]\n",
            "loss: 0.496483 [51264/60000]\n",
            "loss: 0.417931 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.2%, avg_loss 0.470023\n",
            " \n",
            "Epoch: 67\n",
            "-----------------------\n",
            "loss: 0.722674 [   64/60000]\n",
            "loss: 0.373379 [ 6464/60000]\n",
            "loss: 0.673359 [12864/60000]\n",
            "loss: 0.511228 [19264/60000]\n",
            "loss: 0.488317 [25664/60000]\n",
            "loss: 0.453572 [32064/60000]\n",
            "loss: 0.402523 [38464/60000]\n",
            "loss: 0.530538 [44864/60000]\n",
            "loss: 0.527690 [51264/60000]\n",
            "loss: 0.455525 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.5%, avg_loss 0.468738\n",
            " \n",
            "Epoch: 68\n",
            "-----------------------\n",
            "loss: 0.613404 [   64/60000]\n",
            "loss: 0.518359 [ 6464/60000]\n",
            "loss: 0.471696 [12864/60000]\n",
            "loss: 0.380298 [19264/60000]\n",
            "loss: 0.258196 [25664/60000]\n",
            "loss: 0.515722 [32064/60000]\n",
            "loss: 0.520775 [38464/60000]\n",
            "loss: 0.537165 [44864/60000]\n",
            "loss: 0.313449 [51264/60000]\n",
            "loss: 0.568905 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.4%, avg_loss 0.466382\n",
            " \n",
            "Epoch: 69\n",
            "-----------------------\n",
            "loss: 0.479369 [   64/60000]\n",
            "loss: 0.315829 [ 6464/60000]\n",
            "loss: 0.543888 [12864/60000]\n",
            "loss: 0.469968 [19264/60000]\n",
            "loss: 0.371679 [25664/60000]\n",
            "loss: 0.409340 [32064/60000]\n",
            "loss: 0.310484 [38464/60000]\n",
            "loss: 0.254461 [44864/60000]\n",
            "loss: 0.475142 [51264/60000]\n",
            "loss: 0.372139 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.3%, avg_loss 0.468679\n",
            " \n",
            "Epoch: 70\n",
            "-----------------------\n",
            "loss: 0.303010 [   64/60000]\n",
            "loss: 0.601541 [ 6464/60000]\n",
            "loss: 0.370097 [12864/60000]\n",
            "loss: 0.363873 [19264/60000]\n",
            "loss: 0.282200 [25664/60000]\n",
            "loss: 0.268138 [32064/60000]\n",
            "loss: 0.618595 [38464/60000]\n",
            "loss: 0.484247 [44864/60000]\n",
            "loss: 0.512383 [51264/60000]\n",
            "loss: 0.538390 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.5%, avg_loss 0.464013\n",
            " \n",
            "Epoch: 71\n",
            "-----------------------\n",
            "loss: 0.517812 [   64/60000]\n",
            "loss: 0.647580 [ 6464/60000]\n",
            "loss: 0.513943 [12864/60000]\n",
            "loss: 0.468694 [19264/60000]\n",
            "loss: 0.379237 [25664/60000]\n",
            "loss: 0.379534 [32064/60000]\n",
            "loss: 0.548265 [38464/60000]\n",
            "loss: 0.384195 [44864/60000]\n",
            "loss: 0.392309 [51264/60000]\n",
            "loss: 0.424086 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.5%, avg_loss 0.464977\n",
            " \n",
            "Epoch: 72\n",
            "-----------------------\n",
            "loss: 0.380039 [   64/60000]\n",
            "loss: 0.450813 [ 6464/60000]\n",
            "loss: 0.322780 [12864/60000]\n",
            "loss: 0.589481 [19264/60000]\n",
            "loss: 0.325039 [25664/60000]\n",
            "loss: 0.442486 [32064/60000]\n",
            "loss: 0.327149 [38464/60000]\n",
            "loss: 0.345472 [44864/60000]\n",
            "loss: 0.372930 [51264/60000]\n",
            "loss: 0.432157 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.5%, avg_loss 0.462615\n",
            " \n",
            "Epoch: 73\n",
            "-----------------------\n",
            "loss: 0.356188 [   64/60000]\n",
            "loss: 0.507051 [ 6464/60000]\n",
            "loss: 0.459651 [12864/60000]\n",
            "loss: 0.517538 [19264/60000]\n",
            "loss: 0.437219 [25664/60000]\n",
            "loss: 0.376798 [32064/60000]\n",
            "loss: 0.514032 [38464/60000]\n",
            "loss: 0.438537 [44864/60000]\n",
            "loss: 0.328525 [51264/60000]\n",
            "loss: 0.414184 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.4%, avg_loss 0.462856\n",
            " \n",
            "Epoch: 74\n",
            "-----------------------\n",
            "loss: 0.357524 [   64/60000]\n",
            "loss: 0.334423 [ 6464/60000]\n",
            "loss: 0.344397 [12864/60000]\n",
            "loss: 0.343379 [19264/60000]\n",
            "loss: 0.347459 [25664/60000]\n",
            "loss: 0.480760 [32064/60000]\n",
            "loss: 0.545236 [38464/60000]\n",
            "loss: 0.427214 [44864/60000]\n",
            "loss: 0.396902 [51264/60000]\n",
            "loss: 0.389479 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.5%, avg_loss 0.461035\n",
            " \n",
            "Epoch: 75\n",
            "-----------------------\n",
            "loss: 0.458091 [   64/60000]\n",
            "loss: 0.343907 [ 6464/60000]\n",
            "loss: 0.317590 [12864/60000]\n",
            "loss: 0.532516 [19264/60000]\n",
            "loss: 0.273109 [25664/60000]\n",
            "loss: 0.372637 [32064/60000]\n",
            "loss: 0.417677 [38464/60000]\n",
            "loss: 0.345308 [44864/60000]\n",
            "loss: 0.403290 [51264/60000]\n",
            "loss: 0.547493 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.6%, avg_loss 0.459725\n",
            " \n",
            "Epoch: 76\n",
            "-----------------------\n",
            "loss: 0.362769 [   64/60000]\n",
            "loss: 0.243323 [ 6464/60000]\n",
            "loss: 0.535011 [12864/60000]\n",
            "loss: 0.436156 [19264/60000]\n",
            "loss: 0.560701 [25664/60000]\n",
            "loss: 0.463188 [32064/60000]\n",
            "loss: 0.311432 [38464/60000]\n",
            "loss: 0.471269 [44864/60000]\n",
            "loss: 0.445261 [51264/60000]\n",
            "loss: 0.256848 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.460021\n",
            " \n",
            "Epoch: 77\n",
            "-----------------------\n",
            "loss: 0.310239 [   64/60000]\n",
            "loss: 0.409749 [ 6464/60000]\n",
            "loss: 0.629460 [12864/60000]\n",
            "loss: 0.281509 [19264/60000]\n",
            "loss: 0.464110 [25664/60000]\n",
            "loss: 0.297651 [32064/60000]\n",
            "loss: 0.360454 [38464/60000]\n",
            "loss: 0.358359 [44864/60000]\n",
            "loss: 0.460442 [51264/60000]\n",
            "loss: 0.337303 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.455628\n",
            " \n",
            "Epoch: 78\n",
            "-----------------------\n",
            "loss: 0.348426 [   64/60000]\n",
            "loss: 0.359254 [ 6464/60000]\n",
            "loss: 0.325877 [12864/60000]\n",
            "loss: 0.380004 [19264/60000]\n",
            "loss: 0.386718 [25664/60000]\n",
            "loss: 0.382635 [32064/60000]\n",
            "loss: 0.300097 [38464/60000]\n",
            "loss: 0.361116 [44864/60000]\n",
            "loss: 0.322416 [51264/60000]\n",
            "loss: 0.282882 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.459179\n",
            " \n",
            "Epoch: 79\n",
            "-----------------------\n",
            "loss: 0.468526 [   64/60000]\n",
            "loss: 0.353879 [ 6464/60000]\n",
            "loss: 0.336730 [12864/60000]\n",
            "loss: 0.336190 [19264/60000]\n",
            "loss: 0.500130 [25664/60000]\n",
            "loss: 0.361132 [32064/60000]\n",
            "loss: 0.414992 [38464/60000]\n",
            "loss: 0.411019 [44864/60000]\n",
            "loss: 0.449330 [51264/60000]\n",
            "loss: 0.349865 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.456396\n",
            " \n",
            "Epoch: 80\n",
            "-----------------------\n",
            "loss: 0.286522 [   64/60000]\n",
            "loss: 0.427554 [ 6464/60000]\n",
            "loss: 0.361098 [12864/60000]\n",
            "loss: 0.488683 [19264/60000]\n",
            "loss: 0.411363 [25664/60000]\n",
            "loss: 0.447898 [32064/60000]\n",
            "loss: 0.464706 [38464/60000]\n",
            "loss: 0.271636 [44864/60000]\n",
            "loss: 0.649034 [51264/60000]\n",
            "loss: 0.368990 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.453336\n",
            " \n",
            "Epoch: 81\n",
            "-----------------------\n",
            "loss: 0.490623 [   64/60000]\n",
            "loss: 0.400746 [ 6464/60000]\n",
            "loss: 0.406536 [12864/60000]\n",
            "loss: 0.506844 [19264/60000]\n",
            "loss: 0.438084 [25664/60000]\n",
            "loss: 0.306886 [32064/60000]\n",
            "loss: 0.296023 [38464/60000]\n",
            "loss: 0.515372 [44864/60000]\n",
            "loss: 0.443986 [51264/60000]\n",
            "loss: 0.493781 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.9%, avg_loss 0.455133\n",
            " \n",
            "Epoch: 82\n",
            "-----------------------\n",
            "loss: 0.583016 [   64/60000]\n",
            "loss: 0.389242 [ 6464/60000]\n",
            "loss: 0.454679 [12864/60000]\n",
            "loss: 0.537796 [19264/60000]\n",
            "loss: 0.489089 [25664/60000]\n",
            "loss: 0.419534 [32064/60000]\n",
            "loss: 0.506853 [38464/60000]\n",
            "loss: 0.565790 [44864/60000]\n",
            "loss: 0.297188 [51264/60000]\n",
            "loss: 0.324751 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.0%, avg_loss 0.452618\n",
            " \n",
            "Epoch: 83\n",
            "-----------------------\n",
            "loss: 0.344947 [   64/60000]\n",
            "loss: 0.365155 [ 6464/60000]\n",
            "loss: 0.398281 [12864/60000]\n",
            "loss: 0.429444 [19264/60000]\n",
            "loss: 0.387825 [25664/60000]\n",
            "loss: 0.417142 [32064/60000]\n",
            "loss: 0.451625 [38464/60000]\n",
            "loss: 0.282315 [44864/60000]\n",
            "loss: 0.502337 [51264/60000]\n",
            "loss: 0.443810 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.7%, avg_loss 0.454573\n",
            " \n",
            "Epoch: 84\n",
            "-----------------------\n",
            "loss: 0.442498 [   64/60000]\n",
            "loss: 0.251136 [ 6464/60000]\n",
            "loss: 0.428167 [12864/60000]\n",
            "loss: 0.362808 [19264/60000]\n",
            "loss: 0.259539 [25664/60000]\n",
            "loss: 0.324213 [32064/60000]\n",
            "loss: 0.484420 [38464/60000]\n",
            "loss: 0.278134 [44864/60000]\n",
            "loss: 0.429754 [51264/60000]\n",
            "loss: 0.290608 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.9%, avg_loss 0.451608\n",
            " \n",
            "Epoch: 85\n",
            "-----------------------\n",
            "loss: 0.415056 [   64/60000]\n",
            "loss: 0.316104 [ 6464/60000]\n",
            "loss: 0.380387 [12864/60000]\n",
            "loss: 0.321441 [19264/60000]\n",
            "loss: 0.551426 [25664/60000]\n",
            "loss: 0.397612 [32064/60000]\n",
            "loss: 0.332611 [38464/60000]\n",
            "loss: 0.322734 [44864/60000]\n",
            "loss: 0.438425 [51264/60000]\n",
            "loss: 0.215524 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.0%, avg_loss 0.450457\n",
            " \n",
            "Epoch: 86\n",
            "-----------------------\n",
            "loss: 0.495118 [   64/60000]\n",
            "loss: 0.561672 [ 6464/60000]\n",
            "loss: 0.401526 [12864/60000]\n",
            "loss: 0.374496 [19264/60000]\n",
            "loss: 0.430235 [25664/60000]\n",
            "loss: 0.435644 [32064/60000]\n",
            "loss: 0.478830 [38464/60000]\n",
            "loss: 0.326100 [44864/60000]\n",
            "loss: 0.451994 [51264/60000]\n",
            "loss: 0.447308 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 83.9%, avg_loss 0.452021\n",
            " \n",
            "Epoch: 87\n",
            "-----------------------\n",
            "loss: 0.289114 [   64/60000]\n",
            "loss: 0.468383 [ 6464/60000]\n",
            "loss: 0.418776 [12864/60000]\n",
            "loss: 0.467015 [19264/60000]\n",
            "loss: 0.440287 [25664/60000]\n",
            "loss: 0.530794 [32064/60000]\n",
            "loss: 0.546569 [38464/60000]\n",
            "loss: 0.394080 [44864/60000]\n",
            "loss: 0.373852 [51264/60000]\n",
            "loss: 0.429484 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.2%, avg_loss 0.447353\n",
            " \n",
            "Epoch: 88\n",
            "-----------------------\n",
            "loss: 0.271487 [   64/60000]\n",
            "loss: 0.322355 [ 6464/60000]\n",
            "loss: 0.369589 [12864/60000]\n",
            "loss: 0.284057 [19264/60000]\n",
            "loss: 0.387011 [25664/60000]\n",
            "loss: 0.431997 [32064/60000]\n",
            "loss: 0.392263 [38464/60000]\n",
            "loss: 0.247387 [44864/60000]\n",
            "loss: 0.343705 [51264/60000]\n",
            "loss: 0.455414 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.1%, avg_loss 0.448302\n",
            " \n",
            "Epoch: 89\n",
            "-----------------------\n",
            "loss: 0.314732 [   64/60000]\n",
            "loss: 0.340036 [ 6464/60000]\n",
            "loss: 0.600168 [12864/60000]\n",
            "loss: 0.564976 [19264/60000]\n",
            "loss: 0.412406 [25664/60000]\n",
            "loss: 0.327569 [32064/60000]\n",
            "loss: 0.753579 [38464/60000]\n",
            "loss: 0.450537 [44864/60000]\n",
            "loss: 0.356900 [51264/60000]\n",
            "loss: 0.487637 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.1%, avg_loss 0.446687\n",
            " \n",
            "Epoch: 90\n",
            "-----------------------\n",
            "loss: 0.338146 [   64/60000]\n",
            "loss: 0.309968 [ 6464/60000]\n",
            "loss: 0.321400 [12864/60000]\n",
            "loss: 0.448777 [19264/60000]\n",
            "loss: 0.762901 [25664/60000]\n",
            "loss: 0.338719 [32064/60000]\n",
            "loss: 0.295204 [38464/60000]\n",
            "loss: 0.456290 [44864/60000]\n",
            "loss: 0.354846 [51264/60000]\n",
            "loss: 0.518780 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.1%, avg_loss 0.445423\n",
            " \n",
            "Epoch: 91\n",
            "-----------------------\n",
            "loss: 0.401138 [   64/60000]\n",
            "loss: 0.297642 [ 6464/60000]\n",
            "loss: 0.406313 [12864/60000]\n",
            "loss: 0.429004 [19264/60000]\n",
            "loss: 0.368826 [25664/60000]\n",
            "loss: 0.418334 [32064/60000]\n",
            "loss: 0.346239 [38464/60000]\n",
            "loss: 0.449224 [44864/60000]\n",
            "loss: 0.642055 [51264/60000]\n",
            "loss: 0.457817 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.2%, avg_loss 0.445830\n",
            " \n",
            "Epoch: 92\n",
            "-----------------------\n",
            "loss: 0.378613 [   64/60000]\n",
            "loss: 0.301515 [ 6464/60000]\n",
            "loss: 0.350730 [12864/60000]\n",
            "loss: 0.569991 [19264/60000]\n",
            "loss: 0.401260 [25664/60000]\n",
            "loss: 0.487945 [32064/60000]\n",
            "loss: 0.327442 [38464/60000]\n",
            "loss: 0.515134 [44864/60000]\n",
            "loss: 0.287161 [51264/60000]\n",
            "loss: 0.281215 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.1%, avg_loss 0.445403\n",
            " \n",
            "Epoch: 93\n",
            "-----------------------\n",
            "loss: 0.622448 [   64/60000]\n",
            "loss: 0.426552 [ 6464/60000]\n",
            "loss: 0.353126 [12864/60000]\n",
            "loss: 0.380656 [19264/60000]\n",
            "loss: 0.424686 [25664/60000]\n",
            "loss: 0.652866 [32064/60000]\n",
            "loss: 0.392727 [38464/60000]\n",
            "loss: 0.441066 [44864/60000]\n",
            "loss: 0.537089 [51264/60000]\n",
            "loss: 0.527782 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.2%, avg_loss 0.444568\n",
            " \n",
            "Epoch: 94\n",
            "-----------------------\n",
            "loss: 0.449066 [   64/60000]\n",
            "loss: 0.400914 [ 6464/60000]\n",
            "loss: 0.560907 [12864/60000]\n",
            "loss: 0.336353 [19264/60000]\n",
            "loss: 0.492692 [25664/60000]\n",
            "loss: 0.588927 [32064/60000]\n",
            "loss: 0.285817 [38464/60000]\n",
            "loss: 0.342733 [44864/60000]\n",
            "loss: 0.402864 [51264/60000]\n",
            "loss: 0.326527 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.4%, avg_loss 0.443050\n",
            " \n",
            "Epoch: 95\n",
            "-----------------------\n",
            "loss: 0.389924 [   64/60000]\n",
            "loss: 0.367441 [ 6464/60000]\n",
            "loss: 0.396399 [12864/60000]\n",
            "loss: 0.484446 [19264/60000]\n",
            "loss: 0.315689 [25664/60000]\n",
            "loss: 0.504515 [32064/60000]\n",
            "loss: 0.365843 [38464/60000]\n",
            "loss: 0.320481 [44864/60000]\n",
            "loss: 0.450349 [51264/60000]\n",
            "loss: 0.449838 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.1%, avg_loss 0.445884\n",
            " \n",
            "Epoch: 96\n",
            "-----------------------\n",
            "loss: 0.536233 [   64/60000]\n",
            "loss: 0.427159 [ 6464/60000]\n",
            "loss: 0.340064 [12864/60000]\n",
            "loss: 0.460844 [19264/60000]\n",
            "loss: 0.527187 [25664/60000]\n",
            "loss: 0.247096 [32064/60000]\n",
            "loss: 0.296570 [38464/60000]\n",
            "loss: 0.340146 [44864/60000]\n",
            "loss: 0.415687 [51264/60000]\n",
            "loss: 0.357713 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.3%, avg_loss 0.443584\n",
            " \n",
            "Epoch: 97\n",
            "-----------------------\n",
            "loss: 0.512455 [   64/60000]\n",
            "loss: 0.434046 [ 6464/60000]\n",
            "loss: 0.412988 [12864/60000]\n",
            "loss: 0.458170 [19264/60000]\n",
            "loss: 0.778019 [25664/60000]\n",
            "loss: 0.396523 [32064/60000]\n",
            "loss: 0.324907 [38464/60000]\n",
            "loss: 0.395411 [44864/60000]\n",
            "loss: 0.510738 [51264/60000]\n",
            "loss: 0.449921 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.0%, avg_loss 0.444844\n",
            " \n",
            "Epoch: 98\n",
            "-----------------------\n",
            "loss: 0.499748 [   64/60000]\n",
            "loss: 0.292040 [ 6464/60000]\n",
            "loss: 0.439792 [12864/60000]\n",
            "loss: 0.324384 [19264/60000]\n",
            "loss: 0.564713 [25664/60000]\n",
            "loss: 0.460113 [32064/60000]\n",
            "loss: 0.334238 [38464/60000]\n",
            "loss: 0.477491 [44864/60000]\n",
            "loss: 0.332269 [51264/60000]\n",
            "loss: 0.419174 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.3%, avg_loss 0.441160\n",
            " \n",
            "Epoch: 99\n",
            "-----------------------\n",
            "loss: 0.421176 [   64/60000]\n",
            "loss: 0.516909 [ 6464/60000]\n",
            "loss: 0.428593 [12864/60000]\n",
            "loss: 0.370772 [19264/60000]\n",
            "loss: 0.426068 [25664/60000]\n",
            "loss: 0.296719 [32064/60000]\n",
            "loss: 0.597018 [38464/60000]\n",
            "loss: 0.319168 [44864/60000]\n",
            "loss: 0.329259 [51264/60000]\n",
            "loss: 0.392394 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.5%, avg_loss 0.438902\n",
            " \n",
            "Epoch: 100\n",
            "-----------------------\n",
            "loss: 0.606692 [   64/60000]\n",
            "loss: 0.457231 [ 6464/60000]\n",
            "loss: 0.449244 [12864/60000]\n",
            "loss: 0.439680 [19264/60000]\n",
            "loss: 0.353075 [25664/60000]\n",
            "loss: 0.402462 [32064/60000]\n",
            "loss: 0.512224 [38464/60000]\n",
            "loss: 0.363393 [44864/60000]\n",
            "loss: 0.472965 [51264/60000]\n",
            "loss: 0.390522 [57664/60000]\n",
            "Test Error:\n",
            " Accuracy 84.3%, avg_loss 0.438187\n",
            " \n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "#Model Hyper-parameters\n",
        "epochs = 100\n",
        "learning_rate = 1e-3\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "#Calling our training and testing model\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch: {t+1}\\n-----------------------\")\n",
        "    train_model = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_model = test_loop(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO47H6ttYLGx/LN3AeUoc5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}